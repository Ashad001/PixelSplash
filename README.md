# PixelSplash: CNN-Driven Color Assault on Grayscale Imagery

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

## Overview

**PixelSplash** is a Computer Vision course assignment that takes a grayscale world and splashes it with AI-powered color. Using deep learning, this project explores how Convolutional Neural Networks (CNNs) can predict and reconstruct color in imagesâ€”focusing on the 'Horse' class from the CIFAR-10 dataset.

I dived into two core paradigms in image colorization:
1. **Regression:** Predicting exact RGB values for every pixel.
2. **Classification:** Predicting from a set of quantized color classes.

Each paradigm is tested with two architectures:
- A **Standard Encoder-Decoder CNN**
- A **UNet** model with **skip connections** for spatial retention.

This assignment not only satisfies academic requirements but also pushes the creative and technical boundaries of colorization.

## ğŸ¯ Fundamentals of Computer Vision â€“ Assignment Project

This project was built as part of the **Fundamentals of Computer Vision** course. The objective was to practically implement, train, and evaluate image-to-image deep learning models, understanding how CNNs can reconstruct complex image features such as color.

Through this project, I applied foundational CV concepts like:
- Image preprocessing and augmentation
- Encoder-decoder architecture design
- Loss functions for pixel-wise learning
- Evaluation via perceptual and pixel-based metrics

---

## ğŸ”¥ Highlights

- Dual approaches: Regression vs. Classification-based color prediction.
- Comparative study: Standard CNN vs. UNet with skip connections.
- Visualizations of training, predictions, and performance metrics.
- Clean, modular implementation via Jupyter Notebooks.
- Built entirely using Python, Keras, NumPy, and Matplotlib.

---

## ğŸ“ Project Structure

```
PixelSplash/
â”œâ”€â”€ colorization_regression.ipynb      # Regression: CNN & UNet
â”œâ”€â”€ colorization_classification.ipynb  # Classification: CNN & UNet
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ regression_generated_images.png
â”‚   â”œâ”€â”€ regression_progress_report.png
â”‚   â”œâ”€â”€ classification_generated_images.png
â”‚   â””â”€â”€ classification_progress_report.png
â”œâ”€â”€ report/
â”‚   â”œâ”€â”€ report.tex
â”‚   â”œâ”€â”€ report.pdf
â”‚   â””â”€â”€ references.bib
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ LICENSE
â””â”€â”€ README.md
```

---

## ğŸ§  Methodology

### ğŸ”· 1. Regression

- **Goal:** Direct RGB prediction per pixel.
- **Models:** 
  - Basic CNN (Encoder-Decoder)
  - UNet CNN with skip connections
- **Loss:** MSE, MAE
- **Output:** Continuous 3-channel RGB image

### ğŸ”¶ 2. Classification

- **Goal:** Classify each pixel into a color bin (cluster).
- **Preprocessing:** RGB â†’ 24 color clusters via K-Means
- **Loss:** Categorical Cross-Entropy
- **Output:** Probability map â†’ cluster center â†’ RGB

---

## ğŸ§ª Dataset

- **Source:** CIFAR-10
- **Focus:** 'Horse' class
- **Input:** Grayscale (simulated using Lab space L channel)
- **Target:** Original color (RGB or Lab ab channels)

---

## ğŸ“Š Results Summary

- **UNet > CNN:** UNet consistently outperformed the base CNN in both paradigms.
- **Skip Connections Matter:** Better detail reconstruction, smoother edges, and sharper textures.
- **Regression Wins Metrics:** Slightly better MSE, PSNR, and SSIMâ€”but classification gave more vibrant results.
- **Visual Splash:** Regression was more accurate; classification more creative.

---

## ğŸš€ Getting Started

```bash
git clone 
cd PixelSplash

python -m venv venv
source venv/bin/activate        # Windows: venv\Scripts\activate

pip install -r requirements.txt
jupyter notebook
# or
jupyter lab
```

---

## ğŸ“¦ Dependencies

- Python 3.7+
- TensorFlow / Keras
- NumPy
- Scikit-learn (for K-Means)
- Matplotlib
- OpenCV-Python (optional)
- Jupyter

---

## ğŸ”® Future Enhancements

- Use perceptual loss functions (VGG-based).
- Apply Lab color space for better human perception.
- Experiment with attention mechanisms or GANs.
- Extend beyond 'Horse' class or use larger datasets.
- Real-world colorization (e.g., historical photos).

---

## ğŸ“œ License

MIT License â€“ see [LICENSE](LICENSE) for details.

---

## ğŸ™ Acknowledgements

This project was completed as part of the **CS-AI Fundamentals of Computer Vision** course at FAST-NUCES, Karachi. Inspired by works in image-to-image translation and neural colorization literature.

---

> â€œColor is not just a visual propertyâ€”itâ€™s a neural prediction. PixelSplash brings that prediction to life.â€